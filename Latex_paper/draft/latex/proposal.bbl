% $ biblatex auxiliary file $
% $ biblatex bbl format version 3.1 $
% Do not modify the above lines!
%
% This is an auxiliary file used by the 'biblatex' package.
% This file may safely be deleted. It will be recreated by
% biber as required.
%
\begingroup
\makeatletter
\@ifundefined{ver@biblatex.sty}
  {\@latex@error
     {Missing 'biblatex' package}
     {The bibliography requires the 'biblatex' package.}
      \aftergroup\endinput}
  {}
\endgroup


\refsection{0}
  \datalist[entry]{nty/global//global/global}
    \entry{Calvo-Zaragoza}{article}{}
      \name{author}{3}{}{%
        {{hash=2776d49d4e877131b65a36c36f0caaac}{%
           family={Calvo-Zaragoza},
           familyi={C\bibinithyphendelim Z\bibinitperiod},
           given={Jorge},
           giveni={J\bibinitperiod}}}%
        {{hash=aa38ca2a094c61ee8cceea6fb2010c5f}{%
           family={Hajic},
           familyi={H\bibinitperiod},
           given={Jan},
           giveni={J\bibinitperiod}}}%
        {{hash=671831d2435bb021d6c25ece85233023}{%
           family={Pacha},
           familyi={P\bibinitperiod},
           given={Alexander},
           giveni={A\bibinitperiod}}}%
      }
      \strng{namehash}{52c404a7f5aae1ffaf60e1fbffaa6490}
      \strng{fullhash}{52c404a7f5aae1ffaf60e1fbffaa6490}
      \strng{bibnamehash}{52c404a7f5aae1ffaf60e1fbffaa6490}
      \strng{authorbibnamehash}{52c404a7f5aae1ffaf60e1fbffaa6490}
      \strng{authornamehash}{52c404a7f5aae1ffaf60e1fbffaa6490}
      \strng{authorfullhash}{52c404a7f5aae1ffaf60e1fbffaa6490}
      \field{sortinit}{C}
      \field{sortinithash}{4c244ceae61406cdc0cc2ce1cb1ff703}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{For over 50 years, researchers have been trying to teach computers to read music notation, referred to as Optical Music Recognition (OMR). However, this field is still difficult to access for new researchers, especially those without a significant musical background: Few introductory materials are available, and, furthermore, the field has struggled with defining itself and building a shared terminology. In this work, we address these shortcomings by (1) providing a robust definition of OMR and its relationship to related fields, (2) analyzing how OMR inverts the music encoding process to recover the musical notation and the musical semantics from documents, and (3) proposing a taxonomy of OMR, with most notably a novel taxonomy of applications. Additionally, we discuss how deep learning affects modern OMR research, as opposed to the traditional pipeline. Based on this work, the reader should be able to attain a basic understanding of OMR: its objectives, its inherent structure, its relationship to other fields, the state of the art, and the research opportunities it affords.}
      \field{eprinttype}{arXiv}
      \field{issn}{15577341}
      \field{journaltitle}{ACM Computing Surveys}
      \field{number}{4}
      \field{title}{{Understanding Optical Music Recognition}}
      \field{volume}{53}
      \field{year}{2020}
      \verb{doi}
      \verb 10.1145/3397499
      \endverb
      \verb{eprint}
      \verb 1908.03608
      \endverb
      \verb{file}
      \verb :home/pj/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Calvo-Zaragoza et al. - Unknown - Understanding Optical Music Recognition.pdf:pdf
      \endverb
      \keyw{Optical music recognition,music notation,music scores}
    \endentry
    \entry{Gomez2017}{article}{}
      \name{author}{2}{}{%
        {{hash=3c613a6e8e0a93ebc4c0317d5cc4dfb5}{%
           family={Gomez},
           familyi={G\bibinitperiod},
           given={Ashley\bibnamedelima Antony},
           giveni={A\bibinitperiod\bibinitdelim A\bibinitperiod}}}%
        {{hash=281a03e1a68422ff6f0e8df41ae914ec}{%
           family={Sujatha},
           familyi={S\bibinitperiod},
           given={C\bibnamedelima N},
           giveni={C\bibinitperiod\bibinitdelim N\bibinitperiod}}}%
      }
      \strng{namehash}{bf1714d4439c516fa0d26df39b6982c1}
      \strng{fullhash}{bf1714d4439c516fa0d26df39b6982c1}
      \strng{bibnamehash}{bf1714d4439c516fa0d26df39b6982c1}
      \strng{authorbibnamehash}{bf1714d4439c516fa0d26df39b6982c1}
      \strng{authornamehash}{bf1714d4439c516fa0d26df39b6982c1}
      \strng{authorfullhash}{bf1714d4439c516fa0d26df39b6982c1}
      \field{sortinit}{G}
      \field{sortinithash}{62eb2aa29549e4fdbd3cb154ec5711cb}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{This paper presents the detection and removal of staff lines from the image of a music sheet. The music of composers like Mozart, Beethoven, Ravel and Chopin have mostly been preserved and digitized, the same cannot be said for the pieces composed by lesser known musicians, an Optical music recognition system provides the solution to preserving old music. In an OMR system, the first and most important step is the detection and removal of the staff lines, which are horizontal lines running across music sheets on which notes are placed. Staff lines serve as indicators of the notes' pitch and thereby help identify the note. But staff lines are a hindrance when one tries to identify the various musical symbols on a music sheet thus, the first step in most of the OMR systems is staff line detection and removal. In this paper, the removal of the staff lines will be done using two algorithms namely, Line Track Height and Adaptive Line Track Height algorithms. The performance of these algorithms will be analyzed using the parameters introduced at ICDAR (International Conference on Document Analysis and Recognition) 2011 Music Scores Competition: Staff Removal and Writer Identification. These parameters include ER or error rate, precision, recall and f}
      \field{number}{5}
      \field{title}{{Optical Music Recognition: Staffline Detectionand Removal}}
      \field{volume}{6}
      \field{year}{2017}
      \field{pages}{48\bibrangedash 58}
      \range{pages}{11}
      \verb{file}
      \verb :home/pj/coding/python/Music-Sheet-Pitch-Translation/Latex{\_}paper/Optical Music Recognition Staffline Detectionand Removal.pdf:pdf
      \endverb
      \keyw{omr,optical music recognition,staffline detection,staffline removal,stafflines}
    \endentry
    \entry{Pacha2017}{article}{}
      \name{author}{2}{}{%
        {{hash=671831d2435bb021d6c25ece85233023}{%
           family={Pacha},
           familyi={P\bibinitperiod},
           given={Alexander},
           giveni={A\bibinitperiod}}}%
        {{hash=761d31d34df8cd529644640e5f535f5e}{%
           family={Eidenberger},
           familyi={E\bibinitperiod},
           given={Horst},
           giveni={H\bibinitperiod}}}%
      }
      \strng{namehash}{56ec46075cb42f478c46ecc4a57609f1}
      \strng{fullhash}{56ec46075cb42f478c46ecc4a57609f1}
      \strng{bibnamehash}{56ec46075cb42f478c46ecc4a57609f1}
      \strng{authorbibnamehash}{56ec46075cb42f478c46ecc4a57609f1}
      \strng{authornamehash}{56ec46075cb42f478c46ecc4a57609f1}
      \strng{authorfullhash}{56ec46075cb42f478c46ecc4a57609f1}
      \field{sortinit}{P}
      \field{sortinithash}{bb5b15f2db90f7aef79bb9e83defefcb}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Optical Music Recognition (OMR) is a branch of artificial intelligence that aims at automatically recognizing and understanding the content of music scores in images. Several approaches and systems have been proposed that try to solve this problem by using expert knowledge and specialized algorithms that tend to fail at generalization to a broader set of scores, imperfect image scans or data of different formatting. In this paper we propose a new approach to solve OMR by investigating how humans read music scores and by imitating that behavior with machine learning. To demonstrate the power of this approach, we conduct two experiments that teach a machine to distinguish entire music sheets from arbitrary content through frame-by-frame classification and distinguishing between 32 classes of handwritten music symbols which can be a basis for object detection. Both tasks can be performed at high rates of confidence (> 98{\%}) which is comparable to the performance of humans on the same task.}
      \field{isbn}{9781538614174}
      \field{journaltitle}{Proceedings - 16th IEEE International Conference on Machine Learning and Applications, ICMLA 2017}
      \field{title}{{Towards self-learning optical music recognition}}
      \field{volume}{2017-Decem}
      \field{year}{2017}
      \field{pages}{795\bibrangedash 800}
      \range{pages}{6}
      \verb{doi}
      \verb 10.1109/ICMLA.2017.00-60
      \endverb
      \verb{file}
      \verb :home/pj/MEGA/ComVi/paper{\_}writing/Mendeley/papers/pacha2017.pdf:pdf
      \endverb
      \keyw{Dataset,Deep Learning,Music,Optical Music Recognition,document analysis}
    \endentry
    \entry{Rosebrock}{misc}{}
      \name{author}{1}{}{%
        {{hash=ad5eaecc2721564034f710ce9a318887}{%
           family={Rosebrock},
           familyi={R\bibinitperiod},
           given={Adrian},
           giveni={A\bibinitperiod}}}%
      }
      \strng{namehash}{ad5eaecc2721564034f710ce9a318887}
      \strng{fullhash}{ad5eaecc2721564034f710ce9a318887}
      \strng{bibnamehash}{ad5eaecc2721564034f710ce9a318887}
      \strng{authorbibnamehash}{ad5eaecc2721564034f710ce9a318887}
      \strng{authornamehash}{ad5eaecc2721564034f710ce9a318887}
      \strng{authorfullhash}{ad5eaecc2721564034f710ce9a318887}
      \field{sortinit}{R}
      \field{sortinithash}{b9c68a358aea118dfa887b6e902414a7}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{title}{{(Faster) Non-Maximum Suppression in Python - PyImageSearch}}
      \verb{file}
      \verb :home/pj/coding/python/Music-Sheet-Pitch-Translation/Latex{\_}paper/(Faster) Non-Maximum Suppression in Python - PyImageSearch.html:html
      \endverb
      \verb{urlraw}
      \verb https://www.pyimagesearch.com/2015/02/16/faster-non-maximum-suppression-python/
      \endverb
      \verb{url}
      \verb https://www.pyimagesearch.com/2015/02/16/faster-non-maximum-suppression-python/
      \endverb
      \keyw{Non-maxima supression}
    \endentry
    \entry{Shatri2020a}{article}{}
      \name{author}{2}{}{%
        {{hash=360a192605a0525f13d4a8ba49365b3c}{%
           family={Shatri},
           familyi={S\bibinitperiod},
           given={Elona},
           giveni={E\bibinitperiod}}}%
        {{hash=f01574e8c7c9fed8acf0c76910a6a6f7}{%
           family={Fazekas},
           familyi={F\bibinitperiod},
           given={Gy{ö}rgy},
           giveni={G\bibinitperiod}}}%
      }
      \strng{namehash}{2ebc21c66ded7dc6a187b607f766500f}
      \strng{fullhash}{2ebc21c66ded7dc6a187b607f766500f}
      \strng{bibnamehash}{2ebc21c66ded7dc6a187b607f766500f}
      \strng{authorbibnamehash}{2ebc21c66ded7dc6a187b607f766500f}
      \strng{authornamehash}{2ebc21c66ded7dc6a187b607f766500f}
      \strng{authorfullhash}{2ebc21c66ded7dc6a187b607f766500f}
      \field{sortinit}{S}
      \field{sortinithash}{c319cff79d99c853d775f88277d4e45f}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Optical Music Recognition (OMR) is concerned with transcribing sheet music into a machine-readable format. The transcribed copy should allow musicians to compose, play and edit music by taking a picture of a music sheet. Complete transcription of sheet music would also enable more efficient archival. OMR facilitates examining sheet music statistically or searching for patterns of notations, thus helping use cases in digital musicology too. Recently, there has been a shift in OMR from using conventional computer vision techniques towards a deep learning approach. In this paper, we review relevant works in OMR, including fundamental methods and significant outcomes, and highlight different stages of the OMR pipeline. These stages often lack standard input and output representation and standardised evaluation. Therefore, comparing different approaches and evaluating the impact of different processing methods can become rather complex. This paper provides recommendations for future work, addressing some of the highlighted issues and represents a position in furthering this important field of research.}
      \field{eprinttype}{arXiv}
      \field{month}{6}
      \field{title}{{Optical Music Recognition: State of the Art and Major Challenges}}
      \field{year}{2020}
      \verb{doi}
      \verb 10.5281/zenodo.4105964
      \endverb
      \verb{eprint}
      \verb 2006.07885
      \endverb
      \verb{file}
      \verb :home/pj/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Shatri, Fazekas - 2020 - Optical Music Recognition State of the Art and Major Challenges.pdf:pdf
      \endverb
      \verb{urlraw}
      \verb https://arxiv.org/abs/2006.07885v2 http://arxiv.org/abs/2006.07885
      \endverb
      \verb{url}
      \verb https://arxiv.org/abs/2006.07885v2%20http://arxiv.org/abs/2006.07885
      \endverb
    \endentry
    \entry{Wikipedia2013}{article}{}
      \name{author}{1}{}{%
        {{hash=9c677286866aad38f8e9b660f5411814}{%
           family={Wikipedia},
           familyi={W\bibinitperiod}}}%
      }
      \strng{namehash}{9c677286866aad38f8e9b660f5411814}
      \strng{fullhash}{9c677286866aad38f8e9b660f5411814}
      \strng{bibnamehash}{9c677286866aad38f8e9b660f5411814}
      \strng{authorbibnamehash}{9c677286866aad38f8e9b660f5411814}
      \strng{authornamehash}{9c677286866aad38f8e9b660f5411814}
      \strng{authorfullhash}{9c677286866aad38f8e9b660f5411814}
      \field{sortinit}{W}
      \field{sortinithash}{1af34bd8c148ffb32de1494636b49713}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{journaltitle}{The Free Encyclopedia Wikipedia [web page]}
      \field{title}{{Scientific pitch notation}}
      \field{year}{2013}
      \verb{urlraw}
      \verb https://en.wikipedia.org/wiki/Scientific{\_}pitch{\_}notation http://en.wikipedia.org/wiki/Scientific{\_}pitch{\_}notation
      \endverb
      \verb{url}
      \verb https://en.wikipedia.org/wiki/Scientific%7B%5C_%7Dpitch%7B%5C_%7Dnotation%20http://en.wikipedia.org/wiki/Scientific%7B%5C_%7Dpitch%7B%5C_%7Dnotation
      \endverb
    \endentry
  \enddatalist
\endrefsection
\endinput

